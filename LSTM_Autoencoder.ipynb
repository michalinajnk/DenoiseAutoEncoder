{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install scikit-optimize\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose, ConvLSTM3D\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from skopt import BayesSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#Comment this out if You can use GPU instead of CPU\n",
    "\n",
    "# Set the TensorFlow session to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "#PARAMETERS\n",
    "num_of_cv_tuning = 5\n",
    "height, width = 180, 320\n",
    "desired_no_channels = 3\n",
    "batch_size = 2\n",
    "max_frames = 200\n",
    "max_videos = 4\n",
    "max_videos_eval = 3\n",
    "epochs=5\n",
    "iterations = 20\n",
    "window_size=8\n",
    "threshold = 0.5\n",
    "num_windows = max_frames // window_size\n",
    "input_shape = (window_size, height, width, desired_no_channels) #num_widnows,\n",
    "anomaly_label = \"anomaly\"\n",
    "split_train_val_ratio = 0.5\n",
    "model_filepath = '/content/drive/MyDrive/Models/autoencoder.h5'\n",
    "from keras.utils import Sequence\n",
    "\n",
    "#HYPERPARAMETERS\n",
    "param_space = {\n",
    "    'batch_size': (2, 4),\n",
    "}\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, windowed_optical_flows, batch_size, split_train_val_ratio):\n",
    "        self.windowed_optical_flows = windowed_optical_flows\n",
    "        self.batch_size = batch_size\n",
    "        self.split_train_val_ratio = split_train_val_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.windowed_optical_flows) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_samples = self.windowed_optical_flows[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_samples\n",
    "\n",
    "    def get_X_val(self):\n",
    "        split_idx = int(len(self.windowed_optical_flows) * self.split_train_val_ratio)\n",
    "        return np.concatenate(self.windowed_optical_flows[:split_idx])\n",
    "\n",
    "    def get_X_train(self):\n",
    "        split_idx = int(len(self.windowed_optical_flows) * self.split_train_val_ratio)\n",
    "        return np.concatenate(self.windowed_optical_flows[split_idx:-1])\n",
    "\n",
    "    def get_X_test(self):\n",
    "        return self.windowed_optical_flows[-1]\n",
    "\n",
    "def train_model_incremental_with_validation(model, filename, train_paths, max_videos, batch_size, epochs, split_train_val_ratio, iterations, load_weights=False):\n",
    "    start_video = \"\"\n",
    "    total_anomaly_scores = []\n",
    "    data_generator = None\n",
    "    for iteration in tqdm(range(iterations), desc=\"Iteratons\"):\n",
    "      # Load the previously trained model if it exists\n",
    "      if os.path.exists(model_filepath) and load_weights:\n",
    "          model.load_weights(model_filepath)\n",
    "      load_weights = True\n",
    "      windowed_optical_flows, _, start_video = get_windowed_optical_flows_data(train_paths, max_videos, window_size, start_video)\n",
    "      if len(windowed_optical_flows) == 0:\n",
    "          print(\"No more data available, break the iteration loop\")\n",
    "          break\n",
    "      if data_generator is None:\n",
    "          data_generator = DataGenerator(windowed_optical_flows, batch_size, split_train_val_ratio)\n",
    "      else:\n",
    "          data_generator.windowed_optical_flows = windowed_optical_flows\n",
    "\n",
    "      x_train = data_generator.get_X_train()\n",
    "      x_val = data_generator.get_X_val()\n",
    "      x_test = data_generator.get_X_test()\n",
    "\n",
    "      # Perform Bayesian optimization to find optimal hyperparameters\n",
    "      model = set_best_hyperparameters(build_lstm_autoencoder, param_space, x_val, scoring_func)\n",
    "      print(\"X_train shape {}\".format(x_train.shape))\n",
    "      model.fit(x_train, x_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, x_test))\n",
    "\n",
    "      # Evaluate the model on the validation set\n",
    "      total_anomaly_scores.append(validate_model(x_test, model))\n",
    "\n",
    "      del windowed_optical_flows\n",
    "      del x_train, x_val, x_test\n",
    "      # Save the updated model\n",
    "      model.save(model_filepath)\n",
    "    return total_anomaly_scores\n",
    "\n",
    "\n",
    "def resize_frames(frames, target_size):\n",
    "    resized_frames = []\n",
    "    for frame in frames:\n",
    "        frame_data = cv2.imread(frame)\n",
    "        if frame_data is None:\n",
    "            print(f\"Error loading frame: {frame}\")\n",
    "            continue\n",
    "        resized_frame = cv2.resize(frame_data, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        resized_frames.append(resized_frame)\n",
    "    return resized_frames\n",
    "\n",
    "\n",
    "def get_movie_chunk(path, max_frames, start_frame=0):\n",
    "    frame_files = sorted(file for file in os.listdir(path) if file.endswith('.tif'))\n",
    "    num_frames = len(frame_files)\n",
    "    if start_frame >= num_frames:\n",
    "        return None\n",
    "    end_frame = min(start_frame + max_frames, num_frames)\n",
    "    frame_files = frame_files[start_frame:end_frame]\n",
    "    resized_frames = resize_frames([os.path.join(path, file) for file in frame_files], (320, 180))\n",
    "    return np.array(resized_frames)\n",
    "\n",
    "\n",
    "def get_movie(path, max_frames):\n",
    "    frame_files = sorted(file for file in os.listdir(path) if file.endswith('.tif'))\n",
    "    num_frames = len(frame_files)\n",
    "    if num_frames > 0:\n",
    "      # Duplicate frames if the number of frames is smaller than max_frames\n",
    "      if num_frames < max_frames:\n",
    "          duplication_factor = max_frames // num_frames\n",
    "          remaining_frames = max_frames % num_frames\n",
    "          duplicated_frames = frame_files * duplication_factor + frame_files[:remaining_frames]\n",
    "          frame_files += duplicated_frames\n",
    "      elif num_frames > max_frames:\n",
    "          frame_files = frame_files[:max_frames]\n",
    "      else:\n",
    "          frame_files = frame_files\n",
    "      resized_frames = resize_frames([os.path.join(path, file) for file in frame_files], (320, 180))\n",
    "    else:\n",
    "      resized_frames = []\n",
    "    return np.array(resized_frames)\n",
    "\n",
    "\n",
    "def get_data(paths, max_videos, start_video):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    videos_processed = 0\n",
    "    current_path_index = 0\n",
    "    video_paths = []\n",
    "    # Collect all video paths from all directories\n",
    "    for dataset_path in paths:\n",
    "        video_paths.extend(sorted([os.path.join(dataset_path, video_directory) for video_directory in os.listdir(dataset_path)]))\n",
    "    # Find the index of the start_video in the video paths\n",
    "    if start_video:\n",
    "        try:\n",
    "            start_video_index = video_paths.index(start_video)\n",
    "            current_path_index = start_video_index // max_videos\n",
    "            video_paths = video_paths[start_video_index:]\n",
    "        except ValueError:\n",
    "            pass\n",
    "    for video_path in video_paths:\n",
    "        if videos_processed >= max_videos:\n",
    "            break  # Stop processing videos once the desired number is reached\n",
    "        video = get_movie(video_path, max_frames)\n",
    "        print(f\"Video path: {video_path}\")\n",
    "        if video is None or len(video) == 0:\n",
    "            continue\n",
    "        dataset.append(video)\n",
    "        video_labels = extract_labels_from_frames(video_path, anomaly_label)\n",
    "        labels.extend(video_labels)\n",
    "        videos_processed += 1\n",
    "    dataset = [video for video in dataset if video.shape == (max_frames, height, width, desired_no_channels)]\n",
    "    dataset = np.stack(dataset) if len(dataset) > 0 else []\n",
    "    if start_video == \"\":\n",
    "        next_start_video = video_paths[max_videos] if len(video_paths) > max_videos else None\n",
    "    elif current_path_index + 1 < len(paths):\n",
    "        next_start_video = os.path.join(paths[current_path_index + 1], os.listdir(paths[current_path_index + 1])[0])\n",
    "    else:\n",
    "        next_start_video = None\n",
    "    return dataset, labels, next_start_video\n",
    "\n",
    "def extract_labels_from_frames(video_path, substring_to_find):\n",
    "    frame_names = [os.path.basename(frame_path) for frame_path in sorted(glob.glob(os.path.join(video_path, \"*.tif\")))]\n",
    "    labels = [1 if substring_to_find in frame_name else 0 for frame_name in frame_names]\n",
    "    return labels\n",
    "\n",
    "\n",
    "def calculate_max_dimensions(paths):\n",
    "    max_height, max_width, max_frames = 0, 0, 0\n",
    "    for dataset_path in paths:\n",
    "        for video_directory in os.listdir(dataset_path):\n",
    "            video_path = os.path.join(dataset_path, video_directory)\n",
    "            frame_files = [file for file in os.listdir(video_path) if file.endswith('.tif')]\n",
    "            max_frames = max(max_frames, len(frame_files))\n",
    "            for frame_file in frame_files:\n",
    "                frame = cv2.imread(os.path.join(video_path, frame_file), cv2.IMREAD_UNCHANGED)\n",
    "                if frame is None:\n",
    "                    print(f\"Error loading frame: {frame_file}\")\n",
    "                    continue\n",
    "                max_height, max_width = max(max_height, frame.shape[0]), max(max_width, frame.shape[1])\n",
    "    return max_height, max_width, max_frames\n",
    "\n",
    "\n",
    "def generate_optical_flow(frame_files, max_height, max_width):\n",
    "    # Create an empty array to store the optical flow map volume\n",
    "    optical_flow_volume = np.zeros((len(frame_files), max_height, max_width, desired_no_channels), dtype=np.float32)\n",
    "    #print(\"Shape of a frame: {}\".format(frame_files[0].shape))\n",
    "    prev_gray = cv2.cvtColor(frame_files[0], cv2.COLOR_BGR2GRAY)\n",
    "    for frame_index in range(1, len(frame_files)):\n",
    "        frame = frame_files[frame_index]\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        # Store the optical flow in the optical flow map volume\n",
    "        optical_flow_volume[frame_index - 1, :, :, 0] = flow[..., 0]\n",
    "        optical_flow_volume[frame_index - 1, :, :, 1] = flow[..., 1]\n",
    "        # Convert the flow vectors to magnitude and angle\n",
    "        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # Normalize the magnitude to the range [0, 255]\n",
    "        magnitude_normalized = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Convert the angle to the hue channel in the HSV color space\n",
    "        hsv = np.zeros_like(frame)\n",
    "        hsv[..., 0] = angle * (180 / np.pi) / 2  # Hue channel\n",
    "        hsv[..., 1] = 255  # Saturation channel\n",
    "        hsv[..., 2] = magnitude_normalized  # Value channel\n",
    "        # Convert HSV to BGR color representation\n",
    "        rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        # Set the third channel with RGB color values\n",
    "        optical_flow_volume[frame_index - 1, :, :, 2] = rgb[..., 2]\n",
    "        prev_gray = gray\n",
    "    # return flow_volume_map_for_a_video\n",
    "    return optical_flow_volume\n",
    "\n",
    "\n",
    "def calculate_optical_flows(data, max_frame_height, max_frame_width):\n",
    "    optical_flows = []\n",
    "    for video in data:\n",
    "        optical_flow_video = generate_optical_flow(video, max_frame_height, max_frame_width)\n",
    "        optical_flows.append(optical_flow_video)\n",
    "    optical_flows_array = np.stack(optical_flows)\n",
    "    print(f\"dataset shape: {optical_flows_array.shape}\")\n",
    "    return optical_flows_array\n",
    "\n",
    "def update_maximum_dimensions(max_frames, max_height, max_width, optical_flow_video):\n",
    "    # Update the maximum dimensions\n",
    "    max_frames = max(max_frames, optical_flow_video.shape[0])\n",
    "    print(\"Max frames: {} \".format(max_frames))\n",
    "    max_height = max(max_height, optical_flow_video.shape[1])\n",
    "    max_width = max(max_width, optical_flow_video.shape[2])\n",
    "    channels = optical_flow_video.shape[3]\n",
    "    return channels, max_frames, max_height, max_width\n",
    "\n",
    "\n",
    "def divide_into_windows(optical_flow_dataset, window_size):\n",
    "    windowed_dataset = []\n",
    "    for optical_flow_video in optical_flow_dataset:\n",
    "        windows = divide_into_windows_video(optical_flow_video, window_size)\n",
    "        print(f\"Window shape: {windows.shape}\")\n",
    "        windowed_dataset.append(windows)\n",
    "    return windowed_dataset\n",
    "\n",
    "\n",
    "def divide_into_windows_video(video, window_size):\n",
    "    num_frames = video.shape[0]\n",
    "    windows = [video[i:i + window_size] for i in range(0, num_frames, window_size)]\n",
    "    compatible_windows = [window for window in windows if window.shape == (window_size, height, width, desired_no_channels)]\n",
    "    np_windows = np.stack(compatible_windows)\n",
    "    return np_windows\n",
    "\n",
    "\n",
    "def divide_data_into_dirs(moved_from_directory, moved_to_directory, split_ratio):\n",
    "  subdirectories = os.listdir(moved_from_directory)\n",
    "  random.shuffle(subdirectories)\n",
    "  n_subdirectories = len(subdirectories)\n",
    "  n_validation = int(split_ratio * n_subdirectories)\n",
    "  n_test = n_subdirectories - n_validation\n",
    "  if not os.path.exists(moved_to_directory):\n",
    "      os.makedirs(moved_to_directory)\n",
    "  validation_subdirectories = subdirectories[:n_validation]\n",
    "  test_subdirectories = subdirectories[n_validation:]\n",
    "  for subdirectory in validation_subdirectories:\n",
    "      source = os.path.join(moved_from_directory, subdirectory)\n",
    "      destination = os.path.join(moved_to_directory, subdirectory)\n",
    "      shutil.move(source, destination)\n",
    "  # Rename \"Test\" substring to \"Validation\" in validation directory\n",
    "  for root, dirs, files in os.walk(moved_to_directory):\n",
    "      for dir_name in dirs:\n",
    "          if \"Test\" in dir_name:\n",
    "              new_dir_name = dir_name.replace(\"Test\", \"Validation\")\n",
    "              os.rename(os.path.join(root, dir_name), os.path.join(root, new_dir_name))\n",
    "  print(f\"Moved {n_validation} subdirectories to the validation directory: {moved_to_directory}.\")\n",
    "  print(f\"Remaining subdirectories in the test directory: {n_test}.\")\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "def build_lstm_autoencoder():\n",
    "    input_data = Input(shape=input_shape)\n",
    "    encoded = Conv3D(filters=128, kernel_size=(10, 10, 3), activation='relu', padding='same', strides=(2, 2, 1))(input_data)\n",
    "    print(\"Shape in the after first conv3D layer {}\".format(encoded.shape))\n",
    "    encoded = Conv3D(filters=64, kernel_size=(6, 6, 3), activation='relu', padding='same', strides=(2, 2, 1))(encoded)\n",
    "    print(\"Shape in the after second conv3D layer {}\".format(encoded.shape))\n",
    "    encoded = ConvLSTM3D(filters=64, kernel_size=(3, 3, 3), padding='same', return_sequences=True)(encoded[:, None, ...])\n",
    "    print(\"Shape in the after first ConvLSTM layer {}\".format(encoded.shape))\n",
    "    encoded = ConvLSTM3D(filters=32, kernel_size=(3, 3, 3), padding='same', return_sequences=True)(encoded)\n",
    "    print(\"Shape in the after second ConvLSTM layer {}\".format(encoded.shape))\n",
    "    encoded = ConvLSTM3D(filters=64, kernel_size=(3, 3, 3), padding='same', return_sequences=True)(encoded)\n",
    "    print(\"Shape in the after third ConvLSTM layer {}\".format(encoded.shape))\n",
    "    # Decoder\n",
    "    decoded = Conv3DTranspose(filters=128, kernel_size=(6, 6, 3), strides=(2, 2, 1), padding='same', activation='relu')(encoded[:, 0, ...])\n",
    "    print(\"Shape in the after first Conv3DTranspose layer {}\".format(decoded.shape))\n",
    "    decoded = Conv3DTranspose(filters=1, kernel_size=(10, 10, 3), strides=(2, 2, 1), padding='same', activation='relu')(decoded)\n",
    "    print(\"Shape in the after second Conv3DTranspose layer {}\".format(decoded.shape))\n",
    "    decoded = Conv3D(filters=3, kernel_size=(3, 3, 3), activation='sigmoid', padding='same')(decoded)\n",
    "    print(\"Shape in the after third Conv3DTranspose layer {}\".format(decoded.shape))\n",
    "    model = Model(input_data, decoded)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    # Autoencoder model\n",
    "    return model\n",
    "\n",
    "\n",
    "def assign_window_labels(windowed_optical_flows, frame_labels):\n",
    "    window_labels = []\n",
    "    for idx, window_frames in enumerate(windowed_optical_flows):\n",
    "        window_label = 0  # Initialize the window label as normal (0)\n",
    "        for frame in window_frames:\n",
    "            if frame_labels[idx] == 1:  # If any frame in the window is abnormal\n",
    "                window_label = 1  # Set the window label as abnormal (1)\n",
    "                break\n",
    "        window_labels.append(window_label)\n",
    "    return window_labels\n",
    "\n",
    "\n",
    "def get_windowed_optical_flows_data(paths, max_videos, window_size, start_video):\n",
    "  x_train, frame_labels , start_video = get_data(paths, max_videos, start_video)\n",
    "  if len(x_train) == 0:\n",
    "    return [], [], \"\"\n",
    "  print(f\"Shape of training data: {x_train.shape}\")\n",
    "  print(f\"Shape of one video: {np.array(x_train[0]).shape}\")\n",
    "  optical_flows = calculate_optical_flows(x_train, 180, 320)\n",
    "  if len(optical_flows) == 0:\n",
    "   return [], [], \"\"\n",
    "  windowed_optical_flows = divide_into_windows(optical_flows, window_size)\n",
    "  if len(windowed_optical_flows) == 0:\n",
    "    return [], [], \"\"\n",
    "  # Assign window-level labels based on frame-level labels\n",
    "  window_labels = assign_window_labels(windowed_optical_flows, frame_labels)\n",
    "  del optical_flows\n",
    "  return windowed_optical_flows, window_labels, start_video\n",
    "\n",
    "\n",
    "def set_best_hyperparameters(model_fn, param_space, X_val, custom_scoring_func):\n",
    "    # Wrap the Keras model in a scikit-learn compatible wrapper\n",
    "    wrapped_model = KerasRegressor(build_fn=model_fn)\n",
    "    n_splits = min(3, len(X_val)//2)  # Set the number of splits based on the number of samples\n",
    "    opt = BayesSearchCV(wrapped_model, param_space, scoring=custom_scoring_func, cv=n_splits, n_jobs=1)\n",
    "    # Perform Bayesian optimization to find optimal hyperparameters\n",
    "    print(f\"X_val shape == {X_val.shape}\")\n",
    "    opt.fit(X_val, X_val)\n",
    "    # Get the best hyperparameters found by Bayesian optimization\n",
    "    best_hyperparams = opt.best_params_\n",
    "    # Unwrap the model\n",
    "    best_model = opt.best_estimator_.model\n",
    "    # Update the model with the best hyperparameters\n",
    "    best_model.set_params(**best_hyperparams)\n",
    "    # Delete unused variables to free up memory\n",
    "    del wrapped_model\n",
    "    del opt\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def calculate_ms_ssim_error(original_flow, reconstructed_flow):\n",
    "    ms_ssim_error = compare_ssim(original_flow, reconstructed_flow, multichannel=True)\n",
    "    return ms_ssim_error\n",
    "\n",
    "\n",
    "def calculate_anomaly_score(original_flow, reconstructed_flow):\n",
    "  ms_msim_error = calculate_ms_ssim_error(original_flow, reconstructed_flow)\n",
    "  return 1 - ms_msim_error\n",
    "\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_scores = scaler.fit_transform(scores.reshape(-1, 1))\n",
    "    return normalized_scores.flatten()\n",
    "\n",
    "\n",
    "def scoring_func(model, data, y):\n",
    "    reconstructed_flows = model.predict(data)\n",
    "    # Calculate the anomaly scores\n",
    "    anomaly_scores = calculate_anomaly_score(data, reconstructed_flows)\n",
    "    if anomaly_scores:\n",
    "        # Apply your chosen normalization technique here\n",
    "        normalized_scores = normalize_scores(anomaly_scores)\n",
    "    else:\n",
    "        normalized_scores = anomaly_scores\n",
    "    return -np.mean(normalized_scores)\n",
    "\n",
    "\n",
    "def evaluate_model(model, filename, paths, max_frames, threshold, max_videos, start_video, readFromFile=False):\n",
    "  if readFromFile:\n",
    "    # Load the trained model\n",
    "    if os.path.exists(model_filepath):\n",
    "        model = tf.models.load_model(model_filepath)\n",
    "    else:\n",
    "        print(\"Trained model weights not found!\")\n",
    "        return\n",
    "  total_anomaly_scores = []\n",
    "  true_labels = []\n",
    "  windowed_optical_flows, window_labels, start_video = get_windowed_optical_flows_data(paths, max_videos, window_size, start_video)\n",
    "  # Predict the reconstructed optical flows\n",
    "  reconstructed_optical_flows = model.predict(windowed_optical_flows)\n",
    "  # Calculate the anomaly scores for each reconstructed flow\n",
    "  anomaly_scores = []\n",
    "  for i in range(len(reconstructed_optical_flows)):\n",
    "      original_flow = windowed_optical_flows[i]\n",
    "      reconstructed_flow = reconstructed_optical_flows[i]\n",
    "      anomaly_score = calculate_anomaly_score(original_flow, reconstructed_flow)\n",
    "      anomaly_scores.append(anomaly_score)\n",
    "  # Collect the anomaly scores and true labels for all videos\n",
    "  total_anomaly_scores.extend(anomaly_scores)\n",
    "  true_labels.extend(window_labels)  # Assuming `labels` is a list of true anomaly labels\n",
    "  # Convert lists to numpy arrays for evaluation metrics computation\n",
    "  total_anomaly_scores = np.array(total_anomaly_scores)\n",
    "  true_labels = np.array(true_labels)\n",
    "  # Compute precision, recall, and F1-score\n",
    "  precision = precision_score(true_labels, total_anomaly_scores > threshold)\n",
    "  recall = recall_score(true_labels, total_anomaly_scores > threshold)\n",
    "  f1 = f1_score(true_labels, total_anomaly_scores > threshold)\n",
    "  # Print the evaluation metrics\n",
    "  print(\"Precision:\", precision)\n",
    "  print(\"Recall:\", recall)\n",
    "  print(\"F1-score:\", f1)\n",
    "  # Plot the anomaly scores\n",
    "  plt.plot(total_anomaly_scores)\n",
    "  plt.xlabel(\"Frame Index\")\n",
    "  plt.ylabel(\"Anomaly Score\")\n",
    "  plt.title(\"Anomaly Detection\")\n",
    "  plt.show()\n",
    "  return start_video\n",
    "\n",
    "\n",
    "def validate_model(X_val, model):\n",
    "  reconstructed_optical_flows = model.predict(X_val)\n",
    "  # Calculate the anomaly scores for each reconstructed flow\n",
    "  anomaly_scores = []\n",
    "  for i in range(len(reconstructed_optical_flows)):\n",
    "      original_flow = X_val[i]\n",
    "      reconstructed_flow = reconstructed_optical_flows[i]\n",
    "      anomaly_score = calculate_anomaly_score(original_flow, reconstructed_flow)\n",
    "      anomaly_scores.append(anomaly_score)\n",
    "  plot_anomaly_score_distribution(anomaly_scores)\n",
    "  threshold = determine_threshold(anomaly_scores)\n",
    "  plot_anomaly_score_trend(anomaly_scores, threshold)\n",
    "  return anomaly_score\n",
    "\n",
    "\n",
    "\n",
    "def plot_anomaly_score_distribution(anomaly_scores):\n",
    "  plt.hist(anomaly_scores, bins=20, density=True, alpha=0.5)\n",
    "  plt.xlabel('Anomaly Score')\n",
    "  plt.ylabel('Density')\n",
    "  plt.title('Distribution of Anomaly Scores')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true, anomaly_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, anomaly_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_optical_flow_comparison(original_flow, reconstructed_flow):\n",
    "    # Plot the original and reconstructed flows side by side\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    axes[0].imshow(original_flow)\n",
    "    axes[0].set_title('Original Flow')\n",
    "    axes[1].imshow(reconstructed_flow)\n",
    "    axes[1].set_title('Reconstructed Flow')\n",
    "    plt.show()\n",
    "\n",
    "def plot_anomaly_score_trend(anomaly_scores, threshold):\n",
    "    # Plot the anomaly scores over the dataset\n",
    "    plt.plot(anomaly_scores)\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Anomaly Score')\n",
    "    plt.title('Anomaly Score Trend')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def determine_threshold(total_anomaly_scores):\n",
    "    # Calculate the mean and standard deviation of the total_anomaly_scores\n",
    "    mean_score = np.mean(total_anomaly_scores)\n",
    "    std_score = np.std(total_anomaly_scores)\n",
    "    # Plot the histogram of total_anomaly_scores\n",
    "    plot_anomaly_score_distribution(total_anomaly_scores)\n",
    "    # Set the threshold as a multiple of the standard deviation from the mean\n",
    "    threshold = mean_score + 2 * std_score\n",
    "    print(\"Threshold for anomaly detection:\", threshold)\n",
    "    return threshold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    USCDped1_train_path = '/content/drive/MyDrive/UCSDped1/Train'\n",
    "    USCDped2_train_path = '/content/drive/MyDrive/UCSDped2/Train'\n",
    "\n",
    "    USCDped1_test_path = '/content/drive/MyDrive/UCSDped1/Test'\n",
    "    USCDped2_test_path = '/content/drive/MyDrive/UCSDped2/Test'\n",
    "\n",
    "    USCDped1_validation_path = '/content/drive/MyDrive/UCSDped1/Validation'\n",
    "    USCDped2_validation_path = '/content/drive/MyDrive/UCSDped2/Validation'\n",
    "\n",
    "    train_paths = [USCDped1_train_path, USCDped2_train_path]\n",
    "    validation_paths = [USCDped1_validation_path, USCDped2_validation_path]\n",
    "\n",
    "    lstm_autoencoder = build_lstm_autoencoder()\n",
    "    total_anomaly_scores = train_model_incremental_with_validation(lstm_autoencoder, \"autoencoder\", train_paths, max_videos, batch_size, epochs, split_train_val_ratio, iterations)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
