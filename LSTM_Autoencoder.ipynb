{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose, ConvLSTM3D\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#Comment this out if You can use GPU instead of CPU\n",
    "\"\"\"\n",
    "# Set the TensorFlow session to use GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#PARAMETERS\n",
    "optical_flows = []\n",
    "height, width = 180, 320\n",
    "desired_no_channels = 3\n",
    "batch_size = 2\n",
    "max_frames = 200\n",
    "max_videos = 1\n",
    "max_videos_eval = 3\n",
    "epochs=10\n",
    "window_size=8\n",
    "num_windows = max_frames // window_size\n",
    "input_shape = (window_size, height, width, desired_no_channels) #num_widnows,\n",
    "anomaly_label = \"anomaly\"\n",
    "\n",
    "\n",
    "def resize_frames(frames, target_size):\n",
    "    resized_frames = []\n",
    "    for frame in frames:\n",
    "        frame_data = cv2.imread(frame)\n",
    "        if frame_data is None:\n",
    "            print(f\"Error loading frame: {frame}\")\n",
    "            continue\n",
    "        resized_frame = cv2.resize(frame_data, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        resized_frames.append(resized_frame)\n",
    "    return resized_frames\n",
    "\n",
    "\n",
    "def get_movie_chunk(path, max_frames, start_frame=0):\n",
    "    frame_files = sorted(file for file in os.listdir(path) if file.endswith('.tif'))\n",
    "    num_frames = len(frame_files)\n",
    "    if start_frame >= num_frames:\n",
    "        return None\n",
    "    end_frame = min(start_frame + max_frames, num_frames)\n",
    "    frame_files = frame_files[start_frame:end_frame]\n",
    "    resized_frames = resize_frames([os.path.join(path, file) for file in frame_files], (320, 180))\n",
    "    return np.array(resized_frames)\n",
    "\n",
    "\n",
    "def get_movie(path, max_frames):\n",
    "    frame_files = sorted(file for file in os.listdir(path) if file.endswith('.tif'))\n",
    "    num_frames = len(frame_files)\n",
    "    if num_frames > 0:\n",
    "      # Duplicate frames if the number of frames is smaller than max_frames\n",
    "      if num_frames < max_frames:\n",
    "          duplication_factor = max_frames // num_frames\n",
    "          remaining_frames = max_frames % num_frames\n",
    "          duplicated_frames = frame_files * duplication_factor + frame_files[:remaining_frames]\n",
    "          frame_files += duplicated_frames\n",
    "      elif num_frames > max_frames:\n",
    "          frame_files = frame_files[:max_frames]\n",
    "      else:\n",
    "          frame_files = frame_files\n",
    "      resized_frames = resize_frames([os.path.join(path, file) for file in frame_files], (320, 180))\n",
    "    else:\n",
    "      resized_frames = []\n",
    "    return np.array(resized_frames)\n",
    "\n",
    "\n",
    "def get_data(paths, max_videos, start_video):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    last_processed_video = None  # Initialize the variable to keep track of the last processed video\n",
    "    videos_processed = 0  # Keep track of the number of videos processed\n",
    "    current_path_index = 0  # Keep track of the current path index\n",
    "    video_paths = []  # Collect all video paths from all directories\n",
    "    # Collect all video paths from all directories\n",
    "    for dataset_path in paths:\n",
    "        video_paths.extend([os.path.join(dataset_path, video_directory) for video_directory in os.listdir(dataset_path)])\n",
    "    # Find the index of the last processed video in the video paths\n",
    "    if start_video:\n",
    "        print(f\"File path of {start_video}\")\n",
    "        try:\n",
    "            last_processed_video_index = video_paths.index(start_video) if start_video != \"\" else  video_paths[0]\n",
    "            current_path_index = last_processed_video_index // max_videos if start_video != \"\" else 0  # Calculate the current path index\n",
    "            video_paths = video_paths[last_processed_video_index:]  # Adjust the video paths starting from the last processed video\n",
    "        except ValueError:\n",
    "            pass\n",
    "    for video_path in video_paths:\n",
    "        if last_processed_video is not None and video_path != last_processed_video:\n",
    "            continue  # Skip the video if it's not the next video to be processed\n",
    "        video = get_movie(video_path, max_frames)  # Process the entire video at once\n",
    "        if video is None or len(video) == 0:\n",
    "            continue  # Skip if the video is empty\n",
    "        dataset.append(video)\n",
    "        videos_processed += 1\n",
    "        video_labels = extract_labels_from_frames(video_path, anomaly_label)\n",
    "        labels.extend(video_labels)\n",
    "        if videos_processed >= max_videos:\n",
    "            break  # Stop processing videos once the desired number is reached\n",
    "        last_processed_video = video_path\n",
    "    dataset = [video for video in dataset if video.shape == (max_frames, height, width, desired_no_channels)]\n",
    "    dataset = np.stack(dataset) if len(dataset) > 0 else []\n",
    "    # Calculate the next start video based on the current path index\n",
    "    if current_path_index + 1 < len(paths):\n",
    "        next_start_video = os.path.join(paths[current_path_index + 1], os.listdir(paths[current_path_index + 1])[0])\n",
    "    else:\n",
    "        next_start_video = None\n",
    "    return dataset, labels, next_start_video\n",
    "\n",
    "\n",
    "def extract_labels_from_frames(video_path, substring_to_find):\n",
    "    frame_names = [os.path.basename(frame_path) for frame_path in sorted(glob.glob(os.path.join(video_path, \"*.tif\")))]\n",
    "    labels = [1 if substring_to_find in frame_name else 0 for frame_name in frame_names]\n",
    "    return labels\n",
    "\n",
    "\n",
    "def calculate_max_dimensions(paths):\n",
    "    max_height, max_width, max_frames = 0, 0, 0\n",
    "    for dataset_path in paths:\n",
    "        for video_directory in os.listdir(dataset_path):\n",
    "            video_path = os.path.join(dataset_path, video_directory)\n",
    "            frame_files = [file for file in os.listdir(video_path) if file.endswith('.tif')]\n",
    "            max_frames = max(max_frames, len(frame_files))\n",
    "            for frame_file in frame_files:\n",
    "                frame = cv2.imread(os.path.join(video_path, frame_file), cv2.IMREAD_UNCHANGED)\n",
    "                if frame is None:\n",
    "                    print(f\"Error loading frame: {frame_file}\")\n",
    "                    continue\n",
    "                max_height, max_width = max(max_height, frame.shape[0]), max(max_width, frame.shape[1])\n",
    "    return max_height, max_width, max_frames\n",
    "\n",
    "\n",
    "def generate_optical_flow(frame_files, max_height, max_width):\n",
    "    # Create an empty array to store the optical flow map volume\n",
    "    optical_flow_volume = np.zeros((len(frame_files), max_height, max_width, desired_no_channels), dtype=np.float32)\n",
    "    print(\"Shape of a frame: {}\".format(frame_files[0].shape))\n",
    "    prev_gray = cv2.cvtColor(frame_files[0], cv2.COLOR_BGR2GRAY)\n",
    "    for frame_index in range(1, len(frame_files)):\n",
    "        frame = frame_files[frame_index]\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        # Store the optical flow in the optical flow map volume\n",
    "        optical_flow_volume[frame_index - 1, :, :, 0] = flow[..., 0]\n",
    "        optical_flow_volume[frame_index - 1, :, :, 1] = flow[..., 1]\n",
    "        # Convert the flow vectors to magnitude and angle\n",
    "        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # Normalize the magnitude to the range [0, 255]\n",
    "        magnitude_normalized = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Convert the angle to the hue channel in the HSV color space\n",
    "        hsv = np.zeros_like(frame)\n",
    "        hsv[..., 0] = angle * (180 / np.pi) / 2  # Hue channel\n",
    "        hsv[..., 1] = 255  # Saturation channel\n",
    "        hsv[..., 2] = magnitude_normalized  # Value channel\n",
    "        # Convert HSV to BGR color representation\n",
    "        rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        # Set the third channel with RGB color values\n",
    "        optical_flow_volume[frame_index - 1, :, :, 2] = rgb[..., 2]\n",
    "        prev_gray = gray\n",
    "    # return flow_volume_map_for_a_video\n",
    "    print(f\"Optical flow volume shape: {optical_flow_volume.shape}\")\n",
    "    return optical_flow_volume\n",
    "\n",
    "\n",
    "def calculate_optical_flows(data, max_frame_height, max_frame_width):\n",
    "    for video in data:\n",
    "        optical_flow_video = generate_optical_flow(video, max_frame_height, max_frame_width)\n",
    "        optical_flows.append(optical_flow_video)\n",
    "    print(f\"dataset shape: {np.array(optical_flows).shape}\")\n",
    "    return np.array(optical_flows)\n",
    "\n",
    "\n",
    "def update_maximum_dimensions(max_frames, max_height, max_width, optical_flow_video):\n",
    "    # Update the maximum dimensions\n",
    "    max_frames = max(max_frames, optical_flow_video.shape[0])\n",
    "    print(\"Max frames: {} \".format(max_frames))\n",
    "    max_height = max(max_height, optical_flow_video.shape[1])\n",
    "    max_width = max(max_width, optical_flow_video.shape[2])\n",
    "    channels = optical_flow_video.shape[3]\n",
    "    return channels, max_frames, max_height, max_width\n",
    "\n",
    "\n",
    "def divide_into_windows(optical_flow_dataset, window_size):\n",
    "    windowed_dataset = []\n",
    "    for optical_flow_video in optical_flow_dataset:\n",
    "        windows = divide_into_windows_video(optical_flow_video, window_size)\n",
    "        print(f\"Window shape: {windows.shape}\")\n",
    "        windowed_dataset.append(windows)\n",
    "    return windowed_dataset\n",
    "\n",
    "\n",
    "def divide_into_windows_video(video, window_size):\n",
    "    num_frames = video.shape[0]\n",
    "    windows = [video[i:i + window_size] for i in range(0, num_frames, window_size)]\n",
    "    compatible_windows = [window for window in windows if window.shape == (window_size, height, width, desired_no_channels)]\n",
    "    np_windows = np.stack(compatible_windows)\n",
    "    return np_windows\n",
    "\n",
    "\n",
    "def divide_data_into_validation_and_test(test_directory, validation_directory, split_ratio):\n",
    "  subdirectories = os.listdir(test_directory)\n",
    "  random.shuffle(subdirectories)\n",
    "  n_subdirectories = len(subdirectories)\n",
    "  n_validation = int(split_ratio * n_subdirectories)\n",
    "  n_test = n_subdirectories - n_validation\n",
    "  if not os.path.exists(validation_directory):\n",
    "      os.makedirs(validation_directory)\n",
    "  validation_subdirectories = subdirectories[:n_validation]\n",
    "  test_subdirectories = subdirectories[n_validation:]\n",
    "  for subdirectory in validation_subdirectories:\n",
    "      source = os.path.join(test_directory, subdirectory)\n",
    "      destination = os.path.join(validation_directory, subdirectory)\n",
    "      shutil.move(source, destination)\n",
    "  # Rename \"Test\" substring to \"Validation\" in validation directory\n",
    "  for root, dirs, files in os.walk(validation_directory):\n",
    "      for dir_name in dirs:\n",
    "          if \"Test\" in dir_name:\n",
    "              new_dir_name = dir_name.replace(\"Test\", \"Validation\")\n",
    "              os.rename(os.path.join(root, dir_name), os.path.join(root, new_dir_name))\n",
    "  print(f\"Moved {n_validation} subdirectories to the validation directory: {validation_directory}.\")\n",
    "  print(f\"Remaining subdirectories in the test directory: {n_test}.\")\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "def build_lstm_autoencoder(shape):\n",
    "    print(\"Shape in the input_data {}\".format(shape))\n",
    "    input_data = Input(shape=shape)\n",
    "    encoded = Conv3D(filters=128, kernel_size=(10, 10, 3), activation='relu', padding='same', strides=(2, 2, 1))(input_data)\n",
    "    print(\"Shape in the after first conv3D layer {}\".format(encoded.shape))\n",
    "    encoded = Conv3D(filters=64, kernel_size=(6, 6, 3), activation='relu', padding='same', strides=(2, 2, 1))(encoded)\n",
    "    print(\"Shape in the after second conv3D layer {}\".format(encoded.shape))\n",
    "    encoded = ConvLSTM3D(filters=64, kernel_size=(3, 3, 3), padding='same', return_sequences=True)(encoded[:, None, ...])\n",
    "    print(\"Shape in the after first ConvLSTM layer {}\".format(encoded.shape))\n",
    "    encoded = ConvLSTM3D(filters=32, kernel_size=(3, 3, 3), padding='same', return_sequences=True)(encoded)\n",
    "    print(\"Shape in the after second ConvLSTM layer {}\".format(encoded.shape))\n",
    "    encoded = ConvLSTM3D(filters=64, kernel_size=(3, 3, 3), padding='same', return_sequences=True)(encoded)\n",
    "    print(\"Shape in the after third ConvLSTM layer {}\".format(encoded.shape))\n",
    "    # Decoder\n",
    "    decoded = Conv3DTranspose(filters=128, kernel_size=(6, 6, 3), strides=(2, 2, 1), padding='same', activation='relu')(encoded[:, 0, ...])\n",
    "    print(\"Shape in the after first Conv3DTranspose layer {}\".format(decoded.shape))\n",
    "    decoded = Conv3DTranspose(filters=1, kernel_size=(10, 10, 3), strides=(2, 2, 1), padding='same', activation='relu')(decoded)\n",
    "    print(\"Shape in the after second Conv3DTranspose layer {}\".format(decoded.shape))\n",
    "    decoded = Conv3D(filters=3, kernel_size=(3, 3, 3), activation='sigmoid', padding='same')(decoded)\n",
    "    print(\"Shape in the after third Conv3DTranspose layer {}\".format(decoded.shape))\n",
    "    model = Model(input_data, decoded)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    # Autoencoder model\n",
    "    return model\n",
    "\n",
    "\n",
    "def assign_window_labels(windowed_optical_flows, frame_labels):\n",
    "    window_labels = []\n",
    "    for idx, window_frames in enumerate(windowed_optical_flows):\n",
    "        window_label = 0  # Initialize the window label as normal (0)\n",
    "        for frame in window_frames:\n",
    "            if frame_labels[idx] == 1:  # If any frame in the window is abnormal\n",
    "                window_label = 1  # Set the window label as abnormal (1)\n",
    "                break\n",
    "        window_labels.append(window_label)\n",
    "    return window_labels\n",
    "\n",
    "\n",
    "def get_windowed_optical_flows_data(paths, max_videos, window_size, start_video):\n",
    "  x_train, frame_labels , start_video = get_data(paths, max_videos, start_video)\n",
    "  if len(x_train) == 0:\n",
    "    return []\n",
    "  print(f\"Shape of training data: {x_train.shape}\")\n",
    "  print(f\"Shape of one video: {np.array(x_train[0]).shape}\")\n",
    "  optical_flows = calculate_optical_flows(x_train, 180, 320)\n",
    "  if len(optical_flows) == 0:\n",
    "   return []\n",
    "  windowed_optical_flows = divide_into_windows(optical_flows, window_size)\n",
    "  if len(windowed_optical_flows) == 0:\n",
    "    return []\n",
    "  # Assign window-level labels based on frame-level labels\n",
    "  window_labels = assign_window_labels(windowed_optical_flows, frame_labels)\n",
    "  return windowed_optical_flows, window_labels, start_video\n",
    "\n",
    "\n",
    "def train_model_incremental(model, filename, paths, max_frames, max_videos, batch_size, epochs):\n",
    "    # Load the previously trained model if it exists\n",
    "    if os.path.exists(f\"{filename}.h5\"):\n",
    "        model.load_weights(f\"{filename}.h5\")\n",
    "    start_video=\"\"\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "      window_size = 8\n",
    "      windowed_optical_flows, _, start_video = get_windowed_optical_flows_data(paths, max_videos, window_size, start_video)\n",
    "      if len(windowed_optical_flows) == 0:\n",
    "        print(\"No more data available, break the iteration loop\")\n",
    "        break\n",
    "      # Train the model on the current chunk of data\n",
    "      model.fit(x=windowed_optical_flows, y=windowed_optical_flows, batch_size=batch_size, epochs=1)\n",
    "      # Save the updated model\n",
    "      model.save(f\"{filename}.h5\")\n",
    "      del windowed_optical_flows\n",
    "\n",
    "\n",
    "def train_model_incremental_with_validation(model, filename, train_paths, max_frames, max_videos, batch_size, epochs, validation_paths, max_videos_eval):\n",
    "    # Load the previously trained model if it exists\n",
    "    if os.path.exists(f\"{filename}.h5\"):\n",
    "        model.load_weights(f\"{filename}.h5\")\n",
    "    start_video=\"\"\n",
    "    start_video_evaluation = \"\"\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "      window_size = 8\n",
    "      windowed_optical_flows, _, start_video = get_windowed_optical_flows_data(train_paths, max_videos, window_size, start_video)\n",
    "      if len(windowed_optical_flows) == 0:\n",
    "        print(\"No more data available, break the iteration loop\")\n",
    "        break\n",
    "      # Train the model on the current chunk of data\n",
    "      model.fit(x=windowed_optical_flows, y=windowed_optical_flows, batch_size=batch_size, epochs=1)\n",
    "      treshold = 0.5\n",
    "      #evaluate the model on validation set\n",
    "      start_video_evaluation = evaluate_model(model, filename, validation_paths, max_frames, treshold, max_videos_eval, start_video_evaluation)\n",
    "      # Save the updated model\n",
    "      model.save(f\"{filename}.h5\")\n",
    "      del windowed_optical_flows\n",
    "\n",
    "\n",
    "# A higher MS-SSIM value indicates better similarity between the original and reconstructed flow,\n",
    "# indicating a more accurate reconstruction.\n",
    "def calculate_ms_ssim_error(original_flow, reconstructed_flow):\n",
    "    ms_ssim_error = compare_ssim(original_flow, reconstructed_flow, multichannel=True)\n",
    "    return ms_ssim_error\n",
    "\n",
    "\n",
    "def calculate_anomaly_score(original_flow, reconstructed_flow):\n",
    "  ms_msim_error = calculate_ms_ssim_error(original_flow, reconstructed_flow)\n",
    "  return 1 - ms_msim_error\n",
    "\n",
    "\n",
    "def evaluate_model(model, filename, paths, max_frames, threshold, max_videos, start_video, readFromFile=False):\n",
    "  if readFromFile:\n",
    "    # Load the trained model\n",
    "    if os.path.exists(f\"{filename}.h5\"):\n",
    "        model = tf.models.load_model(f\"{filename}.h5\")\n",
    "    else:\n",
    "        print(\"Trained model weights not found!\")\n",
    "        return\n",
    "    total_anomaly_scores = []\n",
    "    true_labels = []\n",
    "    window_size = 8\n",
    "    windowed_optical_flows, window_labels, start_video = get_windowed_optical_flows_data(model, filename, paths, max_frames, max_videos, window_size, start_video)\n",
    "    # Predict the reconstructed optical flows\n",
    "    reconstructed_optical_flows = model.predict(windowed_optical_flows)\n",
    "    # Calculate the anomaly scores for each reconstructed flow\n",
    "    anomaly_scores = []\n",
    "    for i in range(len(reconstructed_optical_flows)):\n",
    "        original_flow = windowed_optical_flows[i]\n",
    "        reconstructed_flow = reconstructed_optical_flows[i]\n",
    "        anomaly_score = calculate_anomaly_score(original_flow, reconstructed_flow)\n",
    "        anomaly_scores.append(anomaly_score)\n",
    "    # Collect the anomaly scores and true labels for all videos\n",
    "    total_anomaly_scores.extend(anomaly_scores)\n",
    "    true_labels.extend(window_labels)  # Assuming `labels` is a list of true anomaly labels\n",
    "    # Convert lists to numpy arrays for evaluation metrics computation\n",
    "    total_anomaly_scores = np.array(total_anomaly_scores)\n",
    "    true_labels = np.array(true_labels)\n",
    "    # Compute precision, recall, and F1-score\n",
    "    precision = precision_score(true_labels, total_anomaly_scores > threshold)\n",
    "    recall = recall_score(true_labels, total_anomaly_scores > threshold)\n",
    "    f1 = f1_score(true_labels, total_anomaly_scores > threshold)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    # Plot the anomaly scores\n",
    "    plt.plot(total_anomaly_scores)\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Anomaly Score\")\n",
    "    plt.title(\"Anomaly Detection\")\n",
    "    plt.show()\n",
    "    return start_video\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    USCDped1_train_path = '/content/drive/MyDrive/UCSDped1/Train'\n",
    "    USCDped2_train_path = '/content/drive/MyDrive/UCSDped2/Train'\n",
    "\n",
    "    USCDped1_test_path = '/content/drive/MyDrive/UCSDped1/Test'\n",
    "    USCDped2_test_path = '/content/drive/MyDrive/UCSDped2/Test'\n",
    "\n",
    "    USCDped1_validation_path = '/content/drive/MyDrive/UCSDped1/Validation'\n",
    "    USCDped2_validation_path = '/content/drive/MyDrive/UCSDped2/Validation'\n",
    "\n",
    "    train_paths = [USCDped1_train_path, USCDped2_train_path]\n",
    "    validation_paths = [USCDped1_validation_path, USCDped2_validation_path]\n",
    "\n",
    "    lstm_autoencoder = build_lstm_autoencoder(input_shape)\n",
    "    train_model_incremental_with_validation(lstm_autoencoder, \"autoencoder\", train_paths, max_frames, max_videos, batch_size, epochs, validation_paths, max_videos_eval)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
